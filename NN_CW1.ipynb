{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Ew3Ws2UqWD8"
   },
   "source": [
    "# DSM150-2022-OCT CW1\n",
    "<i>student number: 210325986</i>\n",
    "\n",
    "---------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qftF7fyzLqYZ"
   },
   "source": [
    "In this notebook I will be building, training, and evaluating a neural network on the CIFAR100 dataset, consisting of 60000 labelled images. The task is a single-label, multi-class classification problem. Following the rubric of the coursework, I will build a neural network using just dense and dropout layers, and test whether it performs better when compared to a baseline model. \n",
    "\n",
    "The notebook is divided into seven sections, corresponding to the machine learning workflow outlined in Chollet (2018)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmvu6GFFLAkl"
   },
   "source": [
    "### **<u>Step 1</u>: Defining Problem and Assembling Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4_8nt7P_M8s"
   },
   "source": [
    "The CIFAR100 dataset, from the Canadian Institute for Advanced Research, is a subset of the Tiny Images dataset and consists of 60000 32x32 color images. The images are grouped into 100 classes ('fine' label), and these classes are in turn grouped into 20 superclasses ('coarse' label). \n",
    "\n",
    "For the purposes of this coursework, I will be using the coarse labels, meaning that the dataset consists of 60000 images divided into 20 classes.\n",
    "\n",
    "The first step is to load the data and the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1X24ytneT-db"
   },
   "outputs": [],
   "source": [
    "#setting random seeds to ensure reproducable results\n",
    "from numpy.random import seed\n",
    "seed(10)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RBRAoJZLIw-i"
   },
   "outputs": [],
   "source": [
    "#loading required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import models, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qTBj-qxI1Eaw"
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "data = cifar100.load_data(label_mode='coarse') #returns tuple of numpy arrays: (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RCk2Mld0YNhy"
   },
   "outputs": [],
   "source": [
    "#dictionary of class labels (provided by dataset source)\n",
    "labels_dict = ({0: 'aquatic_mammals', 1: 'fish', 2: 'flowers', 3: 'food_containers', 4: 'fruit_and_vegetables', 5: 'household_electrical_devices', \n",
    "                6: 'household_furniture', 7: 'insects', 8: 'large_carnivores', 9: 'large_man-made_outdoor_things', 10: 'large_natural_outdoor_scenes',\n",
    "                11: 'large_omnivores_and_herbivores', 12: 'medium_mammals', 13: 'non-insect_invertebrates', 14: 'people', 15: 'reptiles', \n",
    "                16: 'small_mammals', 17: 'trees', 18: 'vehicles_1', 19: 'vehicles_2'} \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LabJYQNoBwvd"
   },
   "source": [
    "The dataset is divided into 50000 training samples and 10000 testing samples. Each sample is a 32x32 RGB colour image, thus giving 3 channels (the depth dimension). Images can only have one label, making this a single-label, multi-class classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hFZ1ofm91La3",
    "outputId": "bf619978-2073-482e-d0a2-71a87dec9c1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = data\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "srVzvDdiCOBm"
   },
   "source": [
    "Confirming (for the training set) that all classes contain the same amount of samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EI24F3KRaays",
    "outputId": "d357056e-dfa4-4970-8434-14ce8e97ada7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (AQUATIC_MAMMALS):  2500\n",
      "1 (FISH):  2500\n",
      "2 (FLOWERS):  2500\n",
      "3 (FOOD_CONTAINERS):  2500\n",
      "4 (FRUIT_AND_VEGETABLES):  2500\n",
      "5 (HOUSEHOLD_ELECTRICAL_DEVICES):  2500\n",
      "6 (HOUSEHOLD_FURNITURE):  2500\n",
      "7 (INSECTS):  2500\n",
      "8 (LARGE_CARNIVORES):  2500\n",
      "9 (LARGE_MAN-MADE_OUTDOOR_THINGS):  2500\n",
      "10 (LARGE_NATURAL_OUTDOOR_SCENES):  2500\n",
      "11 (LARGE_OMNIVORES_AND_HERBIVORES):  2500\n",
      "12 (MEDIUM_MAMMALS):  2500\n",
      "13 (NON-INSECT_INVERTEBRATES):  2500\n",
      "14 (PEOPLE):  2500\n",
      "15 (REPTILES):  2500\n",
      "16 (SMALL_MAMMALS):  2500\n",
      "17 (TREES):  2500\n",
      "18 (VEHICLES_1):  2500\n",
      "19 (VEHICLES_2):  2500\n"
     ]
    }
   ],
   "source": [
    "#printing counts per class\n",
    "label_counts = dict(zip(*np.unique(y_train, return_counts=True)))\n",
    "for key, value in label_counts.items():\n",
    "      print(f'{key} ({labels_dict[key].upper()}):  {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-M4ydYsHLIht"
   },
   "source": [
    "### **<u>Step 2</u>: Defining a Measure of Success**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mKonvIINCtid"
   },
   "source": [
    "It has been shown that the number of samples for each class is equal. Hence, the dataset is balanced. In this situation, an appropriate measure of success for the classifier output is accuracy. \n",
    "\n",
    "The accuracy metric measures the number of correct predictions (true negatives and true positives) as a proportion of total predictions:\n",
    "\n",
    "Accuracy = (TP + TN) / (TP + TN + FP + FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y0mGTlKzLIZV"
   },
   "source": [
    "### **<u>Step 3</u>: Evaluation Protocol** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LwQo_D-dD1aO"
   },
   "source": [
    "Neural networks can be tuned through several non-trainable hyperparameters. One of the more important ones is the number of epochs; i.e. the number of times the entire training set is passed through the model. The optimal number of epochs is not known beforehand; this requires the model to be trained and evaluated on different values for this hyperparameter in order to find the value that maximises performance (based on the chosen performance metric, accuracy). However, the test set cannot be used for this procedure, as this would lead to overfitting when evaluating the final model. This necessitates the need for an additional evaluation protocol for tuning the number of epochs\n",
    "(and possibly other hyperparameters). \n",
    "\n",
    "A common evaluation protocol for smaller datasets is k-fold cross validation. For each value of the hyperparameter being tuned, the training set will be split into k different folds, with the network trained on k-1 of the folds. The network performance will then be evaluated on the  remaining i'th fold, the validation set (i.e. the network's accuracy score on the validation set will be recorded). This process is repreated until all folds have been used once as the validation set. In this way, every training sample forms part of the validation set once, thereby reducing performance variation that can appear in small datasets. The final validation score will be the average accuracy accross all folds. This will be the performance of the network for the current value of the hyperparameter.\n",
    "\n",
    "The process is then repreated for all values of the hyperparameter being evaluated. The optimal number of epochs is the one that achieves the best average performance across the k folds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdUBvx_YKo0s"
   },
   "source": [
    "### **<u>Step 4</u>: Preparing the Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XeU89O1_Hais"
   },
   "source": [
    "Data preparation (including feature extraction) is a critical step in the machine learning workflow, as the quality of the input data will greatly determine the network's performance.\n",
    "\n",
    "In order to prepare the CIFAR100 dataset for input into the neural network, the following pre-processing steps have been identified:\n",
    "\n",
    "1.   Vectorisation\n",
    "2.   Tensor Re-shaping\n",
    "3.   Scaling\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kn51BQDecI8R"
   },
   "source": [
    "The first step is to convert the categorical y labels into one-hot vectors, as machine learning models can only process numerical data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JYxz-96WH8cZ",
    "outputId": "70280781-7c62-4b6d-c0b6-adf62c35bb05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encoding categorical labels\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "y_train[0] #check first observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "luZrNP0OJmQa"
   },
   "source": [
    "The second step is tensor reshaping. The X feature vector currently has the shape (n, 32, 32, 3), as images have three dimensions (width, height, shape), with n being the number of samples. However, dense networks, as will be used in this coursework, require 2D tensors as input. Hence, the input tensors will be re-shaped to (n, 32x32x3) = (n, 3072). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KQhbiXjnHkY-",
    "outputId": "53add2ea-2a16-45ab-d0e3-a9773c1d0d3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (50000, 3072)\n",
      "X_test shape: (10000, 3072)\n"
     ]
    }
   ],
   "source": [
    "#reshape features into 2D tensors\n",
    "X_train = X_train.reshape((50000, 32*32*3)) \n",
    "X_test = X_test.reshape((10000, 32*32*3)) \n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GHRBYu-yJyOM"
   },
   "source": [
    "The third step is scaling the data, since neural networks perform better when working with homogenous data (prevents large gradient updates). Networks also require the input data to be floating-point tensors.\n",
    "\n",
    "Hence, the X features are converted from bytes to floats and scaled to between [0,1] by dividing by 255 (the maximum byte value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "N4WPeWoJJy4G"
   },
   "outputs": [],
   "source": [
    "#converting to float and scaling\n",
    "X_train = X_train.astype('float32') / 255 \n",
    "X_test = X_test.astype('float32') / 255 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbEPKSKga1r5"
   },
   "source": [
    "### **<u>Step 5</u>: Choosing a Baseline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3udYLDtMeLKd"
   },
   "source": [
    "A baseline model is a simple model that acts as a reference to contextualize the results of the trained network.\n",
    "\n",
    "Since this is a single-label classification problem, a useful baseline model would be a random guesser. A random guesser assigns random class labels to each observation. The accuracy of such a model would be 1/c*100. Given that this problem contains c=20 classes, the accuracy of such a random guesser would be 5%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2zNQlbMV3ci"
   },
   "source": [
    "### **<u>Step 6</u>: Network Design**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AuLufewXgFIV"
   },
   "source": [
    "The next step is to design a neural network that is hoped to outperform the baseline on the chosen performance metric. Network design broadly involves three steps:\n",
    "\n",
    "\n",
    "\n",
    "1.   Topology - this refers to the way in which the network is connected. For the scope of this coursework, and in line with the rubric, the network will be sequential, formed of a stack of dense layers.\n",
    "2.   Capacity - this refers to the number of trainable paramters in the model, and is mainly determined by the number of layers and the number of hidden units per layer. Since this is a relatively small dataset, a too large capacity will likely cause overfitting. For this reason, the network will consist of only two hidden layers, the first with 512 hidden units and the second with 256 hidden units. The hidden layers will both use a relu activation, which is preferable in dense layers to tanh or sigmoid. The final output layer will use a softmax activation, outputting a vector of 20 class probabilities.\n",
    "3.   Compilation - this step will determine the learning process of the network. It involves the choice of optimiser and loss function. Since the loss function needs to be continouous and differentiable, the accuracy metric cannot be used as the loss function. Hence, the categorical cross-entropy will be used, common for multi-class, single-label classifications. The optimiser will be RMSprop, which is based on stochastic gradient descent. As explained above, the chosen performance metric will be the accuracy. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "KNawR3iwfdrn"
   },
   "outputs": [],
   "source": [
    "#designing network\n",
    "def neural_network_v1():\n",
    "  '''\n",
    "  Defining a dense network with two hidden layers and categorical cross entropy loss function.\n",
    "  '''\n",
    "\n",
    "  #network architecture \n",
    "  network = models.Sequential() \n",
    "  network.add(layers.Dense(512, activation='relu', input_shape=(3072, ))) \n",
    "  network.add(layers.Dense(256, activation='relu')) \n",
    "  network.add(layers.Dense(20, activation='softmax'))\n",
    "\n",
    "  #compile network \n",
    "  network.compile(optimizer='rmsprop', \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])\n",
    "  \n",
    "  return network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQAfykUAj2oV"
   },
   "source": [
    "The first layer of the network will have (512x3027) weight parameters and 512 bias parameters, for a total of 1,573,376 trainable parameters. \n",
    "\n",
    "The hidden units in the second layer are connected to each of the first layer's units, thus giving (512x256) weight parameters and 256 bias parameters, for a total of 131,328 trainable parameters. Likewise, the final layer will have (256x20) weight parameters and 20 bias parameters, for a total of 5,140.\n",
    "\n",
    "The total number of trainable parameters in the model is thus 1,709,844.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XTyd8AWsjR8F",
    "outputId": "bcb304e3-4b2d-4bed-8a92-8ae8cf5a0084"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               1573376   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 20)                5140      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,709,844\n",
      "Trainable params: 1,709,844\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "neural_network_v1().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWNtLSppksWG"
   },
   "source": [
    "### **<u>Step 7</u>: Tuning & Optimisation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWD3b80FlGXG"
   },
   "source": [
    "The final step in the workflow is to tune the designed model and evaluate it against the baseline, optimising where possible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70_gYNQnlSzV"
   },
   "source": [
    "##### **7.1 Validation & Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-WEE3ellcsm"
   },
   "source": [
    "The below code implements the validation procedure for the designed network. The aim is to tune the 'epochs' hyperparameter. The code uses k=5 folds for the cross validation, and tests for up to 25 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aMkCOhNNV23w",
    "outputId": "0c229a5c-d3d5-48b8-ca9f-b8399c341b2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold 0\n",
      "processing fold 1\n",
      "processing fold 2\n",
      "processing fold 3\n",
      "processing fold 4\n"
     ]
    }
   ],
   "source": [
    "#implementing k fold cross validation\n",
    "\n",
    "#setting variables\n",
    "k = 5 #number of folds\n",
    "n_valid = len(X_train)//k #number of observations in validation set\n",
    "valid_epochs = 25 #number of epochs to test in validation phase\n",
    "training_metrics = []\n",
    "valid_metrics = []\n",
    "\n",
    "#iterating per fold\n",
    "for i in range(k): #i from 0 to 4\n",
    "    print('processing fold', i)\n",
    "    \n",
    "    #set aside validation partition for current fold\n",
    "    lower_bound = i * n_valid\n",
    "    upper_bound = (i + 1) * n_valid\n",
    "    valid_features = X_train[lower_bound:upper_bound]\n",
    "    valid_labels = y_train[lower_bound:upper_bound]\n",
    "    \n",
    "    #remaining data used for training in current fold\n",
    "    train_features = np.concatenate([X_train[:lower_bound], X_train[upper_bound:]], axis=0)\n",
    "    train_labels = np.concatenate([y_train[:lower_bound], y_train[upper_bound:]], axis=0)\n",
    "\n",
    "    #build and train model\n",
    "    valid_network = neural_network_v1()\n",
    "    \n",
    "    training = valid_network.fit(train_features, train_labels,\n",
    "                        validation_data=(valid_features, valid_labels),\n",
    "                        epochs=valid_epochs, batch_size=128, verbose=0)\n",
    "\n",
    "    #storing scores using the 'history' object generated by the .fit() method\n",
    "    training_metrics.append(training.history['loss'])\n",
    "    valid_metrics.append(training.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-QDkLlYofft"
   },
   "source": [
    "The .history object returns a dictionary containing the training and validation metrics. For each of the k folds, each metric contains a list of the model performance across each of the 25 epochs. Choosing the optimal epoch can be done by visualising the training loss against the validation loss (how well the model performs on unseen data) - this can also be done by visualising the  training and validation accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "REtwRavhnhdN",
    "outputId": "ed29d995-d8c3-4c4e-a8aa-13735d24d3cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History metrics: ['loss', 'accuracy', 'val_loss', 'val_accuracy']\n",
      "Number of folds: 5\n",
      "Number of epochs: 25\n"
     ]
    }
   ],
   "source": [
    "print(f'History metrics: {list(training.history.keys())}')\n",
    "print(f'Number of folds: {len(training_metrics)}')\n",
    "print(f'Number of epochs: {len(training_metrics[0])}') #length of first fold scores list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvxvAKI-msmc"
   },
   "source": [
    "Viewing the validation results (after performing exponential smoothing):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "5MJDY9hBMmaA"
   },
   "outputs": [],
   "source": [
    "#define exponential moving average smoothing function\n",
    "def smooth_curve(points, factor = 0.75):\n",
    "  '''\n",
    "  Function to perform exponential smoothing on a list of values.\n",
    "  '''\n",
    "  smoothed_points = []\n",
    "  for point in points:\n",
    "      if smoothed_points: \n",
    "          previous = smoothed_points[-1] #use previous point to smooth current point\n",
    "          smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "      else:\n",
    "          smoothed_points.append(point)\n",
    "  return smoothed_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "MrKXGo9KmZXg",
    "outputId": "847598b0-7b17-4e26-dd36-0559b9a841b8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting validation and training losses to identify optimal number of epochs\n",
    "\n",
    "#average the loss for each epoch accross folds\n",
    "mean_training_loss = [np.mean([x[i] for x in training_metrics]) for i in range(valid_epochs)]\n",
    "mean_valid_loss = [np.mean([x[i] for x in valid_metrics]) for i in range(valid_epochs)]\n",
    "\n",
    "#smoothen the validation loss\n",
    "smooth_valid_loss = smooth_curve(mean_valid_loss)\n",
    "\n",
    "#plotting\n",
    "plt.plot(range(1, valid_epochs + 1), mean_training_loss, label = 'Training')\n",
    "plt.plot(range(1, valid_epochs + 1), smooth_valid_loss, label = 'Validation')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UNHI5ZSuqDmu"
   },
   "source": [
    "From the above chart, it is clear that while training loss falls as epochs increase, the validation loss falls rapidly at first but stalls at around 12 epochs. This is an indication that the network starts to overfit. Hence, the optimal number of epochs appears to be 12."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ouQDwGpuqgzU"
   },
   "source": [
    "##### **7.2 Optimising & Evaluating**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6G33aiBDqh9u"
   },
   "source": [
    "Now that the optimal number of epochs has been identified, the network can be trained on the full training set and evaluated on the previously unseen test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "0XAXz_5OK1BJ"
   },
   "outputs": [],
   "source": [
    "opt_epochs = 12\n",
    "\n",
    "#train on full training set using optimal number of epochs\n",
    "full_network_v1 = neural_network_v1()\n",
    "full_training_v1 = full_network_v1.fit(X_train, y_train, epochs=opt_epochs, batch_size=128, verbose=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Skh8tvSHri48"
   },
   "source": [
    "The .evaluate() method provides the loss and accuracy metric for the tested network. As can be seen, the resulting accuracy is much higher than the 5% achieved by the baseline model, standing at 30%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QRnlyFR9QjTI",
    "outputId": "de91c6de-8c57-4586-9760-95ad819097cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 2.3094 - accuracy: 0.3041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.309396505355835, 0.30410000681877136]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate on test set\n",
    "full_network_v1.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VD5ou7n1r3e-"
   },
   "source": [
    "There are several ways in which the network can be optimised further. Options include adding network capacity, regularisation, or dropout. For the purposes of this coursework, dropout layers will be added after each hidden layer, to test if network performance improves. Dropout randomly drops out a number of output features from a layer during training, which can help break up insignificant noise patterns in the data that might cause overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Jj06QEZ2sVZr"
   },
   "outputs": [],
   "source": [
    "#define network with dropout layers\n",
    "def neural_network_dropout(dr_rate):\n",
    "  '''\n",
    "  Defining a dense network with two hidden layers, two dropout layers, and categorical cross entropy loss function.\n",
    "  '''\n",
    "\n",
    "  #network architecture \n",
    "  network = models.Sequential() \n",
    "  network.add(layers.Dense(512, activation='relu', input_shape=(3072, ))) \n",
    "  network.add(layers.Dropout(dr_rate, seed = 10)) #seed to ensure randomisation is same with every code run\n",
    "  network.add(layers.Dense(256, activation='relu')) \n",
    "  network.add(layers.Dropout(dr_rate, seed = 10))\n",
    "  network.add(layers.Dense(20, activation='softmax'))\n",
    "\n",
    "  #compile network \n",
    "  network.compile(optimizer='rmsprop', \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])\n",
    "  \n",
    "  return network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dBMdGYWgUoZR",
    "outputId": "1de64181-9600-4370-e50e-ae6c4cc0a5fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 2.3353 - accuracy: 0.2848\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.6070 - accuracy: 0.2012\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 2.9143 - accuracy: 0.0776\n"
     ]
    }
   ],
   "source": [
    "#train and evaluate using optimal number of epochs for different dropout rates\n",
    "dropout_scores = {}\n",
    "dropout_vals = [0.25, 0.5, 0.75]\n",
    "for d in dropout_vals:\n",
    "  network_dr = neural_network_dropout(d)\n",
    "  training_dr = network_dr.fit(X_train, y_train, epochs=opt_epochs, batch_size=128, verbose=0)\n",
    "  acc = network_dr.evaluate(X_test, y_test)[-1] #returns list of loss, accuracy - only retain accuracy\n",
    "  dropout_scores[d] = acc #save scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FHYsPtNut6L1"
   },
   "source": [
    "Evaluating on the unseen test set, it can be observed that adding the dropout layers does not lead to any improvement in the network's performance in this case. The best accuracy is 28% with a dropout value of 25% - higher dropout leads to worse performance. One reason could be that the dropout causes the network to lose vital information from the input data. Removing one of the dropout layers, could improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L-J8fNjTWDMH",
    "outputId": "05071534-3d4c-46ba-cd77-27cb6d2a94b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.25: 0.2847999930381775, 0.5: 0.2011999934911728, 0.75: 0.07760000228881836}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#viewing accuracy scores for different dropout rates\n",
    "dropout_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MwZZ4xt_uqbm"
   },
   "source": [
    "### **<u>Concluding Remarks</u>**\n",
    "\n",
    "In this coursework I attempted to fit and evaluate a neural network onto the CIFAR100 dataset. The task was a single-label, multi-class classification of images split into 20 different classes. In line with the coursework rubric, the neural network consisted of a sequential stack of two hidden dense layers and one output layer. k-fold cross validation was used to tune the network and select the optimal number of epochs. \n",
    "\n",
    "The results suggest that the network outperformed a random guesser, chosen as the baseline. An attempt to further improve the model using dropout layers was not successful.\n",
    "\n",
    "Of course, this is just a simple exercise and many improvements could be made. Firstly, the task of image classification would generally require the use of convolutional layers, rather than dense layers. Secondly, attempts could be made to tune other hyperparameters of the model, such as the learning rate. Thirdly, there are several other options that could be used to further improve the network, such as tuning the dropout rate, regularisation, and increasing network capacity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jctP0K3-sQO-"
   },
   "source": [
    "### **<u>References</u>**\n",
    "\n",
    "#### **Websites**\n",
    "https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "https://paperswithcode.com/dataset/cifar-100\n",
    "\n",
    "https://towardsdatascience.com/ultimate-guide-to-input-shape-and-model-complexity-in-neural-networks-ae665c728f4b\n",
    "\n",
    "https://towardsdatascience.com/cifar-10-image-classification-in-tensorflow-5b501f7dc77c\n",
    "\n",
    "https://github.com/deep-diver/CIFAR10-img-classification-tensorflow/blob/master/CIFAR10_image_classification.py\n",
    "\n",
    "#### **Other Material**\n",
    "Chollet, F (2018). *Deep Learning with Python*. Manning Publications Co. ISBN 9781617294433\n",
    "\n",
    "Neural Networks (DSM150-2022-OCT) - lectures & notebooks. University of London."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
